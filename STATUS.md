# ğŸ¯ Status da Stack Big Data - Mini-BigData

**Data de ImplantaÃ§Ã£o:** 22/10/2025  
**VersÃ£o:** 1.0.0  
**Status:** âœ… **OPERACIONAL**

---

## ğŸ“Š Status dos ServiÃ§os

| ServiÃ§o | Status | Porta | URL de Acesso |
|---------|--------|-------|---------------|
| **PostgreSQL** | ğŸŸ¢ Healthy | 5432 | `localhost:5432` |
| **MinIO (S3)** | ğŸŸ¢ Healthy | 9000, 9001 | http://localhost:9001 |
| **Apache Spark Master** | ğŸŸ¢ Running | 7077, 8081 | http://localhost:8081 |
| **Apache Spark Worker** | ğŸŸ¢ Running | 8082 | http://localhost:8082 |
| **Apache Hive Metastore** | ğŸŸ¡ Starting | 9083 | `localhost:9083` |
| **Trino** | ğŸŸ¢ Healthy | 8085 | http://localhost:8085 |
| **Apache Airflow** | ğŸŸ¢ Healthy | 8080 | http://localhost:8080 |
| **Apache Superset** | ğŸŸ¢ Healthy | 8088 | http://localhost:8088 |

---

## ğŸ” Credenciais de Acesso

### MinIO (Object Storage)
- **Console:** http://localhost:9001
- **UsuÃ¡rio:** `minioadmin`
- **Senha:** `minioadmin123`
- **Buckets criados:** bronze, silver, gold, warehouse, raw

### Apache Airflow (OrquestraÃ§Ã£o ETL)
- **UI:** http://localhost:8080
- **UsuÃ¡rio:** `airflow`
- **Senha:** `airflow`

### Apache Superset (BI/Dashboards)
- **UI:** http://localhost:8088
- **UsuÃ¡rio:** `admin`
- **Senha:** `admin`

### Trino (Query Engine)
- **UI:** http://localhost:8085
- **UsuÃ¡rio:** `trino`
- **Sem senha**

### PostgreSQL (Banco de Dados)
- **Host:** `localhost:5432`
- **UsuÃ¡rio:** `admin`
- **Senha:** `admin123`
- **Databases:** `airflow`, `superset`, `metastore`

---

## ğŸ’¾ Armazenamento de Dados

**LocalizaÃ§Ã£o:** `/media/marcelo/dados1/bigdata-docker/`

```
/media/marcelo/dados1/bigdata-docker/
â”œâ”€â”€ airflow/
â”‚   â”œâ”€â”€ dags/       # DAGs do Airflow
â”‚   â”œâ”€â”€ logs/       # Logs do Airflow
â”‚   â””â”€â”€ plugins/    # Plugins personalizados
â”œâ”€â”€ hive/           # Warehouse do Hive
â”œâ”€â”€ minio/          # Dados do MinIO (S3)
â”œâ”€â”€ postgres/       # Dados do PostgreSQL
â”œâ”€â”€ spark/
â”‚   â”œâ”€â”€ master/     # Work directory do Spark Master
â”‚   â””â”€â”€ worker/     # Work directory do Spark Worker
â”œâ”€â”€ superset/       # Dados do Superset
â””â”€â”€ trino/          # Dados do Trino
```

---

## ğŸ› ï¸ Ajustes Realizados

### 1. Hive Metastore - Driver PostgreSQL
**Problema:** Imagem oficial nÃ£o contÃ©m driver JDBC do PostgreSQL  
**SoluÃ§Ã£o:** Criado Dockerfile customizado em `config/hive/Dockerfile` que:
- Instala `wget` e `curl`
- Baixa driver PostgreSQL JDBC (42.7.1)
- Configura variÃ¡veis de ambiente

### 2. Apache Spark - Imagem Oficial
**Problema:** Imagens Bitnami indisponÃ­veis (manifest unknown)  
**SoluÃ§Ã£o:** Migrado para imagem oficial `apache/spark:3.5.3`

### 3. Apache Airflow - DependÃªncias
**Problema:** Conflito de dependÃªncias com protobuf  
**SoluÃ§Ã£o:** Removida variÃ¡vel `_PIP_ADDITIONAL_REQUIREMENTS` que causava conflitos

### 4. Apache Superset - ConfiguraÃ§Ã£o
**Problema:** Erro "No application module specified"  
**SoluÃ§Ã£o:** 
- Adicionada instalaÃ§Ã£o de `psycopg2-binary`
- Ajustado comando de inicializaÃ§Ã£o para `/usr/bin/run-server.sh`
- Adicionadas variÃ¡veis de ambiente para conexÃ£o com PostgreSQL

---

## ğŸš€ Como Usar

### Iniciar a Stack
```bash
cd /home/marcelo/central/mini-bigdata
docker compose up -d
```

### Parar a Stack
```bash
docker compose down
```

### Ver Logs
```bash
# Todos os serviÃ§os
docker compose logs -f

# ServiÃ§o especÃ­fico
docker compose logs -f airflow-webserver
docker compose logs -f spark-master
```

### Verificar Status
```bash
docker compose ps
```

### Reconstruir Imagem do Hive
```bash
docker compose build hive-metastore
docker compose up -d --force-recreate hive-metastore
```

---

## ğŸ“ PrÃ³ximos Passos

1. âœ… **Aguardar inicializaÃ§Ã£o completa** (2-3 minutos apÃ³s `docker compose up -d`)
2. âœ… **Acessar interfaces web** e validar login
3. ğŸ“‹ **Executar pipeline de exemplo:** Ativar DAG `etl_sales_pipeline` no Airflow
4. ğŸ” **Validar dados no Trino:**
   ```sql
   SELECT * FROM hive.sales.sales_silver LIMIT 10;
   ```
5. ğŸ“Š **Criar dashboard no Superset** conectando ao Trino

---

## ğŸ”§ Troubleshooting

### ServiÃ§o nÃ£o estÃ¡ healthy
```bash
# Ver logs do serviÃ§o
docker compose logs <service-name> --tail 50

# Reiniciar serviÃ§o
docker compose restart <service-name>
```

### Airflow nÃ£o aparece UI
```bash
# Verificar se o banco foi inicializado
docker compose logs airflow-init

# Recriar containers
docker compose up -d --force-recreate airflow-webserver airflow-scheduler
```

### Hive Metastore com problema
```bash
# Rebuild da imagem
docker compose build hive-metastore --no-cache
docker compose up -d --force-recreate hive-metastore
```

### Limpar tudo e comeÃ§ar do zero
```bash
docker compose down -v
docker compose up -d
```

---

## ğŸ“š DocumentaÃ§Ã£o Adicional

- **README.md:** DocumentaÃ§Ã£o principal do projeto
- **QUICKSTART.md:** Guia rÃ¡pido de inÃ­cio
- **STORAGE.md:** Detalhes sobre persistÃªncia de dados
- **TROUBLESHOOTING.md:** Guia de resoluÃ§Ã£o de problemas
- **examples/:** Exemplos de DAGs, Jobs PySpark e queries

---

## âœ… Checklist de ValidaÃ§Ã£o

- [x] PostgreSQL rodando e healthy
- [x] MinIO rodando e buckets criados
- [x] Spark Master e Worker rodando
- [x] Hive Metastore inicializado (aguardando healthy)
- [x] Trino rodando e healthy
- [x] Airflow webserver e scheduler rodando
- [x] Superset rodando e healthy
- [x] Todos os dados persistidos em `/media/marcelo/dados1/bigdata-docker/`
- [ ] Pipeline de exemplo executado com sucesso
- [ ] Dashboard criado no Superset

---

**ğŸ‰ Stack estÃ¡ operacional e pronta para uso!**

Para mais informaÃ§Ãµes, consulte a documentaÃ§Ã£o em `README.md` ou execute:
```bash
./check-storage.sh
```
